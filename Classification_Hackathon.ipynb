{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Hackathon.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdebruyn/PackageName/blob/master/Classification_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXPLN3eqxli",
        "colab_type": "text"
      },
      "source": [
        "# Classification Hackathon\n",
        "\n",
        "For the specifications for today's Hackathon use the slides linked below. Just note a couple things before you start:\n",
        "* Use your full name and ```_EDSA``` as your Zindi username.\n",
        "* The dataset for this challenge is very large and will take a long time to process. In order to use your time wisely, only use a small subset of the data to figure out how to solve this challenge, and once you're happy with that, train your model with the entire dataset.\n",
        "* This Zindi challenge is tough. This will be taken into account when the supervisors mark your work. Do not worry too much about your placement on the leaderboard. In the Regression Hackathon ```laura_the_explorer``` was in first place but is outside the top 100 in this challenge\n",
        "* To submit your Hackathon to Athena, zip your notebook and your submission csv file, and upload that here. Note that your report card will say you have 100% once you submit your file.\n",
        "* Please attach the *Honour code* (below) cell to your notebook. \n",
        "\n",
        "Further instructions found on these slides: https://docs.google.com/presentation/d/1AbVndI5aOd27Jm0E1qNoYzRtWiZ6-DE3BDE0djGxzIk/edit?usp=sharing\n",
        "\n",
        "** Good luck! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbR-kHPaqxlk",
        "colab_type": "text"
      },
      "source": [
        "## Honour Code\n",
        "I Chad, de Bruyn, confirm - by submitting my - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
        "\n",
        "Non-compliance with the honour code constitutes a material breach of contract."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwkJx2sqxll",
        "colab_type": "text"
      },
      "source": [
        "# Xente Fraud Detection Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5gQq1Mjqxlm",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zSYOUvumetB",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors.nearest_centroid import NearestCentroid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRj947_4qxlt",
        "colab_type": "text"
      },
      "source": [
        "The competition training and test data sets are imported and then combined into one larger data set so that when dummy variables are later created, both sets will have the same number of these variables. This will prevent any errors when training models and using these models for prediction on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ffTGCq7JmuTh",
        "colab": {}
      },
      "source": [
        "# import the competition data sets\n",
        "train = pd.read_csv('training.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "df = pd.concat([train, test], sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJxsMFExqxly",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fE2oKUlqxlz",
        "colab_type": "text"
      },
      "source": [
        "This is what the data set looks like..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0qLM5z3qxl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9f65b94d-0629-4510-847a-d8b1a41fefce"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionId</th>\n",
              "      <th>BatchId</th>\n",
              "      <th>AccountId</th>\n",
              "      <th>SubscriptionId</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CurrencyCode</th>\n",
              "      <th>CountryCode</th>\n",
              "      <th>ProviderId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>ProductCategory</th>\n",
              "      <th>ChannelId</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Value</th>\n",
              "      <th>TransactionStartTime</th>\n",
              "      <th>PricingStrategy</th>\n",
              "      <th>FraudResult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TransactionId_76871</td>\n",
              "      <td>BatchId_36123</td>\n",
              "      <td>AccountId_3957</td>\n",
              "      <td>SubscriptionId_887</td>\n",
              "      <td>CustomerId_4406</td>\n",
              "      <td>UGX</td>\n",
              "      <td>256</td>\n",
              "      <td>ProviderId_6</td>\n",
              "      <td>ProductId_10</td>\n",
              "      <td>airtime</td>\n",
              "      <td>ChannelId_3</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>2018-11-15T02:18:49Z</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TransactionId_73770</td>\n",
              "      <td>BatchId_15642</td>\n",
              "      <td>AccountId_4841</td>\n",
              "      <td>SubscriptionId_3829</td>\n",
              "      <td>CustomerId_4406</td>\n",
              "      <td>UGX</td>\n",
              "      <td>256</td>\n",
              "      <td>ProviderId_4</td>\n",
              "      <td>ProductId_6</td>\n",
              "      <td>financial_services</td>\n",
              "      <td>ChannelId_2</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>20</td>\n",
              "      <td>2018-11-15T02:19:08Z</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TransactionId_26203</td>\n",
              "      <td>BatchId_53941</td>\n",
              "      <td>AccountId_4229</td>\n",
              "      <td>SubscriptionId_222</td>\n",
              "      <td>CustomerId_4683</td>\n",
              "      <td>UGX</td>\n",
              "      <td>256</td>\n",
              "      <td>ProviderId_6</td>\n",
              "      <td>ProductId_1</td>\n",
              "      <td>airtime</td>\n",
              "      <td>ChannelId_3</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500</td>\n",
              "      <td>2018-11-15T02:44:21Z</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TransactionId_380</td>\n",
              "      <td>BatchId_102363</td>\n",
              "      <td>AccountId_648</td>\n",
              "      <td>SubscriptionId_2185</td>\n",
              "      <td>CustomerId_988</td>\n",
              "      <td>UGX</td>\n",
              "      <td>256</td>\n",
              "      <td>ProviderId_1</td>\n",
              "      <td>ProductId_21</td>\n",
              "      <td>utility_bill</td>\n",
              "      <td>ChannelId_3</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>21800</td>\n",
              "      <td>2018-11-15T03:32:55Z</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TransactionId_28195</td>\n",
              "      <td>BatchId_38780</td>\n",
              "      <td>AccountId_4841</td>\n",
              "      <td>SubscriptionId_3829</td>\n",
              "      <td>CustomerId_988</td>\n",
              "      <td>UGX</td>\n",
              "      <td>256</td>\n",
              "      <td>ProviderId_4</td>\n",
              "      <td>ProductId_6</td>\n",
              "      <td>financial_services</td>\n",
              "      <td>ChannelId_2</td>\n",
              "      <td>-644.0</td>\n",
              "      <td>644</td>\n",
              "      <td>2018-11-15T03:34:21Z</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         TransactionId         BatchId  ... PricingStrategy FraudResult\n",
              "0  TransactionId_76871   BatchId_36123  ...               2         0.0\n",
              "1  TransactionId_73770   BatchId_15642  ...               2         0.0\n",
              "2  TransactionId_26203   BatchId_53941  ...               2         0.0\n",
              "3    TransactionId_380  BatchId_102363  ...               2         0.0\n",
              "4  TransactionId_28195   BatchId_38780  ...               2         0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dUevhHsqxl6",
        "colab_type": "text"
      },
      "source": [
        "And the size of the data set..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlqNQEgRqxl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88d7da5b-3631-4b46-d45a-a4b26cad4732"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140681, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw56o2YZqxmB",
        "colab_type": "text"
      },
      "source": [
        "It is important to establish which variable uniquely identifies each row. Also, if one categorical variable has too many levels, this might be computationally exhaustive and cause crashes when creating dummy variables. Below, each variable is shown with its associated number of unique levels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i3i5mfn2oyuj",
        "outputId": "173dce40-fcf7-4c93-8c0f-cc9bcc0faa37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for column in df.columns:\n",
        "  print(column, ': ', len(np.unique(df[column].values)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TransactionId :  140681\n",
            "BatchId :  139493\n",
            "AccountId :  4841\n",
            "SubscriptionId :  4836\n",
            "CustomerId :  7479\n",
            "CurrencyCode :  1\n",
            "CountryCode :  1\n",
            "ProviderId :  6\n",
            "ProductId :  27\n",
            "ProductCategory :  10\n",
            "ChannelId :  5\n",
            "Amount :  2099\n",
            "Value :  1880\n",
            "TransactionStartTime :  138574\n",
            "PricingStrategy :  4\n",
            "FraudResult :  45021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8fxjXzYqxmI",
        "colab_type": "text"
      },
      "source": [
        "'TransactionId' definitely acts as a dataframe index, as the number of unique levels of this variable is the same as the number of rows in the data set. Great! Also, take a look at 'BatchId', 'AccountId', 'SubscriptionId' and 'CustomerId'. These categorical variables have too many unique values, so when trying to 'dummify' them, the notebook will likely experience problems and might even crash! As a result, these features will be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URJwVJGtEP_O",
        "colab": {}
      },
      "source": [
        "# remove features with too many unique levels\n",
        "df = df.drop(['BatchId', 'AccountId', 'SubscriptionId', 'CustomerId'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUn_wJOnqxmO",
        "colab_type": "text"
      },
      "source": [
        "Have a look at 'CurrencyCode' and 'CountryCode' above. There is only one level of each used throughout the data set. This is not meaningful for modeling purposes, so these features will also be removed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMreiwkSqxmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['CurrencyCode', 'CountryCode'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HYwFPXaqxmU",
        "colab_type": "text"
      },
      "source": [
        "Too many variables are being removed. To prevent 'TransactionStartTime' from being removed, it will first be investigated a little. If only the first 10 characters in this variables are used, i.e. the date in the form yyyy-mm-dd, then there are only 120 unique dates. This is shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXWnCsFqxmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6feb73c-6bc6-44fc-9a49-7363bc0dbeac"
      },
      "source": [
        "len(np.unique(df.apply(lambda x: x['TransactionStartTime'][0:10], axis=1)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bccS-b_HqxmZ",
        "colab_type": "text"
      },
      "source": [
        "As a result, each instance of 'TransactionStartTime' will be changed to the abovementioned format. This will beome a new column being 'TransactionDate', and the original 'TransactionStartTime' will be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opH7aIF6qxma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the date format and create the new column\n",
        "df.loc[:, 'TransactionDate'] = df.apply(lambda x: x['TransactionStartTime'][0:10], axis=1)\n",
        "# remove the old date column\n",
        "df = df.drop('TransactionStartTime', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNBdvAkMqxme",
        "colab_type": "text"
      },
      "source": [
        "Having a look at the data types of all variables in the data set, observe that 'PricingStrategy' is an integer, when it should be of object-type. This change will be made below.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qu6Pst6fsIRc",
        "outputId": "7aa1e775-1148-4e7d-9b78-6601c1b6000f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 140681 entries, 0 to 45018\n",
            "Data columns (total 10 columns):\n",
            "TransactionId      140681 non-null object\n",
            "ProviderId         140681 non-null object\n",
            "ProductId          140681 non-null object\n",
            "ProductCategory    140681 non-null object\n",
            "ChannelId          140681 non-null object\n",
            "Amount             140681 non-null float64\n",
            "Value              140681 non-null int64\n",
            "PricingStrategy    140681 non-null int64\n",
            "FraudResult        95662 non-null float64\n",
            "TransactionDate    140681 non-null object\n",
            "dtypes: float64(2), int64(2), object(6)\n",
            "memory usage: 11.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LjcgDbwswByX",
        "colab": {}
      },
      "source": [
        "# change 'PricingStrategy' to object-type\n",
        "df.loc[:, 'PricingStrategy'] = df['PricingStrategy'].astype('object')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xct6K-x6qxmr",
        "colab_type": "text"
      },
      "source": [
        "Now all that is left to do is to create those dummy variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHe6KnVkqxmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the transaction ids to insert into the data frame after creating dummy variables\n",
        "df_ids = df['TransactionId']\n",
        "# create dummy variables\n",
        "df = pd.get_dummies(df.iloc[:, 1:], drop_first=True)\n",
        "# return the transaction ids\n",
        "df['TransactionId'] = df_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_pQ0boqxmu",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ltVEZTqxmv",
        "colab_type": "text"
      },
      "source": [
        "The data set will now be split back into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUbBBN9qxmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[:len(train)]\n",
        "test = df[len(train):]\n",
        "test = test.drop('FraudResult', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRgWgNCMqxm1",
        "colab_type": "text"
      },
      "source": [
        "Have a look at the imbalance of this data set with regards to the 'FraudResult' label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbCJejwSqxm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "222a7ca9-127c-40bc-a0cd-972331e64cf9"
      },
      "source": [
        "print('The number of non-fraudulent cases: ', len(train[train['FraudResult']==0.0]))\n",
        "print('The number of fraudulent cases: ', len(train[train['FraudResult']==1.0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of non-fraudulent cases:  95469\n",
            "The number of fraudulent cases:  193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVw1rr1fqxm8",
        "colab_type": "text"
      },
      "source": [
        "The data set is evidently very imbalanced. One possible way around this is to take a sample of the training set so that the fraudulent and non-fraudulent cases are equally-represented. This is done below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy87sPhqqxm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non-fraudulent subset\n",
        "train_0 = train.loc[train['FraudResult']==0.0, :]\n",
        "# fraudulent subset\n",
        "train_1 = train.loc[train['FraudResult']==1.0, :]\n",
        "# create a new data set with equal representation of the two subsets\n",
        "train = pd.concat([train_0.sample(len(train_1)), train_1])\n",
        "# create the training set of labels\n",
        "y_train = train['FraudResult']\n",
        "# create a training set of only features\n",
        "X_train = train.drop(['FraudResult', 'TransactionId'], axis=1)\n",
        "# create a test set of only features\n",
        "X_test = test.iloc[:, :-1]\n",
        "# keep the test ids for later use\n",
        "test_ids = test['TransactionId']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huMRSVCbqxnA",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcC7t8GrqxnA",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression\n",
        "Firstly, a logistic model will be fitted on the training set. The subsequent accuracy score will be returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMAAD2GOqxnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4471c12-a9ab-458d-ae24-a35a9d99b732"
      },
      "source": [
        "lr = LogisticRegression(C=0.1, solver='lbfgs', multi_class='multinomial')\n",
        "lr.fit(X_train, y_train)\n",
        "print('Logtistic regression accuracy: ', accuracy_score(y_train, lr.predict(X_train)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logtistic regression accuracy:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT2qcH0YqxnE",
        "colab_type": "text"
      },
      "source": [
        "This model, unfortunately, is very unaccurate, and only correctly predicts half of the cases correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCYwgrIBqxnF",
        "colab_type": "text"
      },
      "source": [
        "### Nearest Centroid\n",
        "Secondly, a nearest centroid model will be fitted on the training set. The subsequent accuracy score will be returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dnDAZhc0CgWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea87db0-6241-4f3d-b8a9-3a743398628c"
      },
      "source": [
        "nc = NearestCentroid()\n",
        "nc.fit(X_train, y_train)\n",
        "print('Nearest centroid accuracy: ', accuracy_score(y_train, nc.predict(X_train)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest centroid accuracy:  0.7072538860103627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8GPjUuhqxnJ",
        "colab_type": "text"
      },
      "source": [
        "That's much better! This model will now be used to predict the test set's labels, and the consequent labels and their associated transaction ids will be saved to CSV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "233Rzme9qxnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict the test labels and create a dataframe with these labels and their associated transaction ids\n",
        "predictions = pd.DataFrame([test_ids, nc.predict(X_test)]).T\n",
        "# change the column names of this dataframe\n",
        "predictions.columns = ['TransactionId', 'FraudResult']\n",
        "# save this dataframe to CSV\n",
        "predictions.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}